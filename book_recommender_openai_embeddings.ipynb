{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a8ab9158",
      "metadata": {
        "id": "a8ab9158"
      },
      "source": [
        "# ðŸ“š Book Recommendation System using OpenAI Embeddings\n",
        "This notebook demonstrates how to build a simple book recommendation system using OpenAI's `text-embedding-ada-002` model. It includes loading and cleaning data, generating embeddings, and recommending similar books based on cosine similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c2a8779",
      "metadata": {
        "id": "7c2a8779"
      },
      "source": [
        "## 1. ðŸ“¦ Import Libraries and Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83bdfb79",
      "metadata": {
        "id": "83bdfb79"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set API Key (you should replace this with your own key securely)\n",
        "os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Load the books dataset\n",
        "df = pd.read_csv(\"books_dataset.csv\")\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Select top 3000 books by rating\n",
        "df = df.sort_values('average_rating', ascending=False).head(3000)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f18bc7b7",
      "metadata": {
        "id": "f18bc7b7"
      },
      "source": [
        "## 2. ðŸ”¢ Count Tokens and Estimate Embedding Cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29211623",
      "metadata": {
        "id": "29211623"
      },
      "outputs": [],
      "source": [
        "# Install the tiktoken library used for tokenizing text (quietly, without extra output)\n",
        "!pip install tiktoken -q\n",
        "import tiktoken\n",
        "\n",
        "# Load the tokenizer specific to the 'text-embedding-ada-002' model\n",
        "enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
        "\n",
        "# Extract the 'description' column from the DataFrame as a list of strings\n",
        "description = list(df['description'])\n",
        "\n",
        "# Calculate the total number of tokens across all book descriptions\n",
        "# Each description is tokenized using the model's tokenizer, and token counts are summed\n",
        "total_tokens = sum([len(enc.encode(item)) for item in description])\n",
        "\n",
        "# Display the total token count\n",
        "print(f'Total tokens: {total_tokens}')\n",
        "\n",
        "# Estimate the cost in USD based on OpenAI's embedding pricing\n",
        "# The current rate is $0.0001 per 1,000 tokens\n",
        "cost = total_tokens * (0.0001 / 1000)\n",
        "\n",
        "# Print the estimated cost, formatted to 10 decimal places\n",
        "print(f'Estimated cost in USD: {cost:.10F}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3effb528",
      "metadata": {
        "id": "3effb528"
      },
      "source": [
        "## 3. ðŸ§  Generate and Save Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b59a3aec",
      "metadata": {
        "id": "b59a3aec"
      },
      "outputs": [],
      "source": [
        "# Define a function to generate an embedding (vector representation) for a given text\n",
        "def get_embedding(text):\n",
        "    response = openai.embeddings.create(\n",
        "        input=text,  # The input text to be embedded\n",
        "        model='text-embedding-ada-002'  # The OpenAI model used for generating embeddings\n",
        "    )\n",
        "    return response.data[0].embedding  # Return the embedding vector from the response\n",
        "\n",
        "# Define a function to compute embeddings for all book descriptions and save them to a CSV file\n",
        "def get_embeddings_and_save_to_csv(embedding_cache_file):\n",
        "    # Apply the embedding function to each description and store the result in a new 'embedding' column\n",
        "    df['embedding'] = df['description'].apply(lambda x: get_embedding(x))\n",
        "\n",
        "    # Save the DataFrame (with embeddings) to a CSV file\n",
        "    df.to_csv(embedding_cache_file)\n",
        "\n",
        "# Specify the filename where the embeddings will be saved\n",
        "embedding_cache_file = 'book_embeddings.csv'\n",
        "\n",
        "# Generate embeddings and save the updated DataFrame to the specified CSV file\n",
        "get_embeddings_and_save_to_csv(embedding_cache_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dec9b0e9",
      "metadata": {
        "id": "dec9b0e9"
      },
      "source": [
        "## 4. ðŸ’¾ Load and Prepare Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c6c1ca",
      "metadata": {
        "id": "c0c6c1ca"
      },
      "outputs": [],
      "source": [
        "# Specify the path to the CSV file containing the saved embeddings\n",
        "embedding_cache_file = 'book_embeddings.csv'\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df_embeddings = pd.read_csv(embedding_cache_file)\n",
        "\n",
        "# Convert the string representation of the embedding back to a NumPy array\n",
        "# First, eval() turns the string into a Python list, then np.array() converts it to a NumPy array\n",
        "df_embeddings['embedding'] = df_embeddings['embedding'].apply(eval).apply(np.array)\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify the data\n",
        "df_embeddings.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24053026",
      "metadata": {
        "id": "24053026"
      },
      "source": [
        "## 5. ðŸ“š Recommend Similar Books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da58c8bf",
      "metadata": {
        "id": "da58c8bf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity  # Import function to compute cosine similarity\n",
        "\n",
        "# Define a function to get top-k similar book recommendations based on a given book title\n",
        "def get_recommendation_from_title(df_embeddings, title, k):\n",
        "    # Check if the given title exists in the dataset\n",
        "    if title not in df_embeddings['title'].values:\n",
        "        return False  # Return False if the title is not found\n",
        "\n",
        "    # Ensure all embeddings are NumPy arrays (in case they are not)\n",
        "    df_embeddings['embedding'] = df_embeddings['embedding'].apply(lambda x: np.array(x))\n",
        "\n",
        "    # Get the embedding for the selected book title and reshape it to match input shape for cosine similarity\n",
        "    target_embedding = df_embeddings.loc[df_embeddings['title'] == title, 'embedding'].values[0].reshape(1, -1)\n",
        "\n",
        "    # Calculate cosine similarity between the target book and all other books\n",
        "    similarities = df_embeddings['embedding'].apply(\n",
        "        lambda x: cosine_similarity(target_embedding, x.reshape(1, -1))[0][0]\n",
        "    )\n",
        "\n",
        "    # Store the similarity scores in a new column\n",
        "    df_embeddings['similarity'] = similarities\n",
        "\n",
        "    # Sort the DataFrame by similarity in descending order (most similar first)\n",
        "    df_sorted = df_embeddings.sort_values(by='similarity', ascending=False)\n",
        "\n",
        "    # Build the list of recommended books (excluding the input book itself)\n",
        "    recommendations = []\n",
        "    for _, row in df_sorted.iloc[0:k+1].iterrows():  # +1 to account for the input book being included\n",
        "        book = {\n",
        "            'title': row['title'],\n",
        "            'description': row['description'],\n",
        "            'similarity': row['similarity']\n",
        "        }\n",
        "        recommendations.append(book)\n",
        "\n",
        "    return recommendations  # Return the list of recommended books\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "get_recommendation_from_title(df_embeddings, 'Colossians and Philemon', 10)"
      ],
      "metadata": {
        "id": "_86fojLouM4U"
      },
      "id": "_86fojLouM4U",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}